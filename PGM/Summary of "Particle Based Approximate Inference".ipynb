{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Summary of *Chapter 12: Particle Based Approximate Inference*\n",
    "\n",
    "This notebook is meant to make the topics discussed in the final week of Coursera's *Probabilistic Graphical Models 2: Inference* more concrete through code examples. This corresponds approximately with chapter 12 of Daphne Koller's book *Probabilistic Graphical Models*. This notebook uses the book as an outline, and not the video lectures. It is recommended you either watch the video lectures or read the chapter to learn the material, and use this notebook as a review sheet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal**: We have some distribution $P(X)$ and want to estimate the probability of an event $Y = y$, $Y \\subseteq X$, $y \\in Val(Y)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 12.1: Forward Sampling \n",
    "\n",
    "Sample directly from $B$, the bayesian network representation of $P$, by sampling from each node's CPD in topological order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![student network](student_network.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our bayesian network $B$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is valid model: True\n"
     ]
    }
   ],
   "source": [
    "from pgmpy.models import BayesianModel\n",
    "from pgmpy.factors.discrete import TabularCPD\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "# Defining the model structure\n",
    "model = BayesianModel([('D', 'G'), ('I', 'G'), ('G', 'L'), ('I', 'S')])\n",
    "\n",
    "# Defining individual CPDs\n",
    "cpd_d = TabularCPD(variable='D', variable_card=2, values=[[0.6, 0.4]])\n",
    "cpd_i = TabularCPD(variable='I', variable_card=2, values=[[0.7, 0.3]])\n",
    "cpd_g = TabularCPD(variable='G', variable_card=3, \n",
    "                   values=[[0.3, 0.05, 0.9,  0.5],\n",
    "                           [0.4, 0.25, 0.08, 0.3],\n",
    "                           [0.3, 0.7,  0.02, 0.2]],\n",
    "                  evidence=['I', 'D'],\n",
    "                  evidence_card=[2, 2])\n",
    "cpd_l = TabularCPD(variable='L', variable_card=2, \n",
    "                   values=[[0.1, 0.4, 0.99],\n",
    "                           [0.9, 0.6, 0.01]],\n",
    "                   evidence=['G'],\n",
    "                   evidence_card=[3])\n",
    "cpd_s = TabularCPD(variable='S', variable_card=2,\n",
    "                   values=[[0.95, 0.2],\n",
    "                           [0.05, 0.8]],\n",
    "                   evidence=['I'],\n",
    "                   evidence_card=[2])\n",
    "\n",
    "# Associating the CPDs with the network\n",
    "model.add_cpds(cpd_d, cpd_i, cpd_g, cpd_l, cpd_s)\n",
    "\n",
    "# check_model checks for the network structure and CPDs and verifies that the CPDs are correctly \n",
    "# defined and sum to 1.\n",
    "print(\"is valid model:\", model.check_model())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I</th>\n",
       "      <th>S</th>\n",
       "      <th>D</th>\n",
       "      <th>G</th>\n",
       "      <th>L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   I  S  D  G  L\n",
       "0  0  0  1  1  0\n",
       "1  1  1  1  1  1\n",
       "2  0  0  0  1  1\n",
       "3  0  0  1  2  0\n",
       "4  0  0  0  0  1\n",
       "5  0  0  1  2  0\n",
       "6  0  0  0  1  0\n",
       "7  1  1  1  1  0\n",
       "8  1  1  0  1  0\n",
       "9  0  0  0  1  0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pgmpy.sampling import BayesianModelSampling\n",
    "forward_sampler = BayesianModelSampling(model)\n",
    "forward_sampler.forward_sample(size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has the advantage of being simple and samples are independent -- so we may apply the Hoeffding bound to get an absolute bound on the error of our estimate of an expected value for any given variable (or set of variables) in the network. We could alternatively use the Chernoff bound to get a relative bound on the error (But we would need a decent guess of the actual expected value beforehand)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get an estimate whose error is bounded by $\\epsilon$, with probability at least $1-\\delta$, we need to draw $M$ samples. Where $M$ satisfies:\n",
    "\n",
    "$$\n",
    "M \\geq \\frac{ln(2/\\delta)}{2\\epsilon^2}\n",
    "$$\n",
    "\n",
    "Assuming we want an error less than or equal to 0.01 with 99% probability, we would need 26,492 samples. Note that we are implicitely assuming that the expected value of our estimate is greater than 0.01 and less than 0.99 (in the binary variable case), otherwise our error bound is too large to be meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimate of marginal:\t0.4976219236\n",
      "actual marginal:\t0.502336\n",
      "difference:\t\t0.00471407640042\n"
     ]
    }
   ],
   "source": [
    "N = 26492\n",
    "sample_set = forward_sampler.forward_sample(N)\n",
    "\n",
    "# estimate expected value of the binary variable L(etter)\n",
    "marginal_estimate = sample_set.loc[:,'L'].sum() / N\n",
    "\n",
    "# use exact inference to get actual marginal of L\n",
    "from pgmpy.inference import VariableElimination\n",
    "inference = VariableElimination(model)\n",
    "marginal_actual = inference.query(['L'])['L']\n",
    "\n",
    "print(\"estimate of marginal:\", marginal_estimate, sep=\"\\t\")\n",
    "print(\"actual marginal:\", marginal_actual.values[1], sep=\"\\t\")\n",
    "print(\"difference:\", abs(marginal_actual.values[1] - marginal_estimate), sep=\"\\t\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the convergence of our estimate to the true expected value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def track_expectation(sample, variable):\n",
    "    cumulative_sums = [0]\n",
    "    for i in range(len(sample)):\n",
    "        cumulative_sums.append(sample.loc[i,variable] + cumulative_sums[i])\n",
    "    cumulative_sums = cumulative_sums[1:]\n",
    "    return np.array([cumulative_sums[i]/(i+1) for i in range(len(cumulative_sums))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exp_l = track_expectation(sample_set, 'L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f1a3ec2eeb8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0MAAAIFCAYAAAAQtiYqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1a42bde1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "domain = np.arange(0, N)\n",
    "true_value = [marginal_actual.values[1]] * len(domain)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.xscale('log')\n",
    "plt.plot(domain, exp_l[domain], 'b', domain, true_value, 'r')\n",
    "plt.legend([\"estimate\", \"true marginal\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see how useful it is to have probabilistic guarantees as to how erroneous our estimate might be. Even past 1000 samples (a typical size for a national survey) our estimate is still quite bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 12.1.1: Rejection Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To estimate a conditional probability given some evidence, $P(Y\\,|\\,E=e)$, we may use *rejection sampling* where we only consider samples where $E=e$ when computing our estimate.\n",
    "\n",
    "Suppose we are interested in $E(L\\, |\\, D=1,\\, S=1) = P(L=1\\, |\\, D=1,\\, S=1)$.\n",
    "\n",
    "Our estimate using the previous sample set would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimate of marginal:\t0.595613433859\n",
      "actual marginal:\t0.577272727273\n",
      "difference:\t\t0.0183407065861\n"
     ]
    }
   ],
   "source": [
    "# estimate\n",
    "valid_samples = sample_set[(sample_set.D == 1) & (sample_set.S == 1)]\n",
    "\n",
    "marginal_w_evidence_estimate = valid_samples.loc[:,'L'].sum() / len(valid_samples)\n",
    "\n",
    "# actual\n",
    "marginal_w_evidence_actual = inference.query(['L'], evidence={'D': 1, 'S': 1})['L']\n",
    "\n",
    "print(\"estimate of marginal:\", marginal_w_evidence_estimate, sep=\"\\t\")\n",
    "print(\"actual marginal:\", marginal_w_evidence_actual.values[1], sep=\"\\t\")\n",
    "print(\"difference:\", abs(marginal_w_evidence_actual.values[1] - marginal_w_evidence_estimate), sep=\"\\t\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our estimate is now worse than before. This isn't surprising considering we are using fewer samples than previously in our estimate. About 11% of our samples should be consistent with 'D' = 1 and 'S' = 1 ($P(D=1) \\times P(S=1)$), so we must draw nearly 10 times as many samples to get the same quality estimate. This might not seem like too much of a problem, but in a larger network with more evidence, where $P(E=e) \\leq 0.001$ is pretty plausible, we're going to be drawing for a long, long time to get the same 0.99 confidence that we are within 0.01 of our estimate. (We must draw $\\frac{M}{P(E=e)}$ times to get a sufficient number of samples, where $M$ is the number of samples we would need to draw without any evidence). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we would like to be able to assign each of the evidence variables to their observed value beforehand, then sample from that distribution. Naively, we could proceed as usual with forward sampling, and if we happen to come across a variable for which we have evidence for, assign that variable to its observed value with probability 1. But this will cause us to sample from an incorrect distribution when sampling from the parent nodes of an observed value, since there is an active trail from the node for which we have evidence for to its parents. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 12.2: Likelihood-Weighted Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To eliminate the useless samples that don't conform to our evidence produced by rejection sampling and avoid biasing our estimate by sampling from incorrect parent distributions, we use a technique called \"likelihood-weighted sampling\". This method is more or less self-explanatory. We use the same naive forward sampling algorithm wherein we set the evidence variables to their observed values, but we then weight each sample by its likelihood given the parent values of the evidence variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![student network](student_network.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The student network reproduced again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in the previous case where we were interested in $P(L=1\\, |\\, D=1,\\, S=1)$, suppose we generate a sample $(D = 1, I=0, S=1, G=3, L=1)$ via our naive forward sampling with evidence technique. We then weight the sample by how likely we were to sample the evidence values given their parents. So, given that $I=0$, we would expect to see $S=1$ 5 percent of the time, and we would expect to see $D=1$ 40 percent of the time. So our sample is worth $0.05*0.4=0.02$ of a sample. We can then proceed as usual with our probabilistic bounds to arrive at a reliable estimate.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I</th>\n",
       "      <th>S</th>\n",
       "      <th>D</th>\n",
       "      <th>G</th>\n",
       "      <th>L</th>\n",
       "      <th>_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   I  S  D  G  L  _weight\n",
       "0  0  1  1  2  0     0.02\n",
       "1  0  1  1  2  0     0.02\n",
       "2  0  1  1  2  0     0.02\n",
       "3  0  1  1  1  0     0.02\n",
       "4  0  1  1  2  0     0.02"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pgmpy.factors.discrete import State\n",
    "\n",
    "weighted_sampler = BayesianModelSampling(model)\n",
    "weighted_samples = weighted_sampler.likelihood_weighted_sample(\n",
    "    evidence = [State('D', 1), State('S', 1)],\n",
    "    size = N)\n",
    "weighted_samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples produced via rejection sampling:\t2918\n",
      "'samples' produced via likelihood-weighting:\t2887.84\n"
     ]
    }
   ],
   "source": [
    "print(\"samples produced via rejection sampling:\", \n",
    "      len(valid_samples), sep=\"\\t\")\n",
    "print(\"'samples' produced via likelihood-weighting:\", \n",
    "      weighted_samples['_weight'].sum(), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparable in number of samples generated, but likelihood-weighting is more efficient since it uses every sample generated in its estimate and can sometimes converge quicker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likelihood-weighted sampling is a special case of a more general approach called \"importance sampling\" wherein we generate samples from a *proposal distribution* $Q(X)$, different from the actual distribution $P(X)$, then adjust for the bias introduced by $Q(X)$. The (very) general idea being:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}_{P(X)}[\\,f(X)] = \\mathbb{E}_{Q(X)}\\left [\\,f(X)\\frac{P(X)}{Q(X)}\\right ]\n",
    "$$\n",
    "\n",
    "Which should be read as \"the expectation of some statistic $f(X)$ with respect to the actual distribution $P(X)$ is equivalent to the expection of a properly weighted $\\left (w = \\frac{P(X)}{Q(X)} \\right )$ statistic $f(x)$ with respect to a proposal distribution $Q(X)$\". This can come in handy when sampling from $Q(X)$ is easier than sampling from $P(X)$. For the theoretical intuition see section 12.2.2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Also discussed in chapter 12:** an implementation of importance sampling (mutilated network), likelihood-weighting for unconditional probabilities, ratio likelihood weighting, normalized likelihood weighting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two weaknesses of likelihood-weighted sampling come to mind: The obvious weakness being that we are unable to apply this method to Markov networks, the not as obvious weakness being that evidence variables only directly influence their children, whereas parent variables are accounted for by weights. This means that if our evidence is contained entirely in the leaves, then we are essentially sampling from the prior distribution of the network, which, likely being far from the desired posterior distribution we would like to sample from, will converge slowly. To remedy these issues, we may use *Markov Chain Monte Carlo* methods. Not only can MCMC allow us to sample from a general network of factors, but it also allows us to sample from a distribution that gets progressively closer to the true posterior. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 12.3 Markov Chain Monte Carlo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 12.3.1 Gibbs Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gibbs sampling is one such MCMC method. The idea being:\n",
    "\n",
    "1. Sample a point $x^{(0)}$ from a prior distribution $P^{(0)}$ by forward sampling from the original distribution, importance sampling, sampling a random state from the uniform distribution while assuming independence, or some other method. In general, the closer $P^{(0)}$ is to $P$ the faster our chain will converge to the desired stationary distribution.\n",
    "2. Iterate through each variable $x_i$ except evidence $e$ by sampling from $P(X_i\\,|\\,x_{-i}, e)$. Use $x^{(t-1)}$ as the initial variable values in $x_{-i}$, but as we sample in each iteration from $P(X_i\\,|\\,x_{-i}, e)$ \"replace\" each variable value in $x^{(t-1)}$ with the new sampled value.\n",
    "3. Once all variables of interest have been iterated over, we now have $x^{(t)}$.\n",
    "4. Repeat until mixing, then we may begin sampling (using the same process) from a distribution that resembles the posterior distribution we actually want to sample from."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain $P(X_i|x_{-i}, e)$, we simply multiply together all factors that contain $X_i$ then renormalize. We don't care about the other factors because they don't affect our algorithm (See *Example 12.4* for a more precise reason):\n",
    "\n",
    "$$\n",
    "P(L\\,|\\,D=1, S=1) = \\frac{P(L\\,|\\,g)}{\\sum_{l}^{} P(l\\,|\\,g)}\n",
    "$$\n",
    "\n",
    "We have G = g from $x^{(t-1)}$, thus the evidence variables have no effect on our sampling distribution for L. BUT, they would have an effect on $P(G\\,|\\,I,D)$ and $P(I)$ since the queried variable shares a scope in some factor with one or more evidence variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pgmpy.sampling import GibbsSampling\n",
    "gibbs = GibbsSampling(model)\n",
    "gibbs_sample = gibbs.sample(size = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimate of P(L=1):\t0.526\n",
      "marginal of P(L=1):\t0.502336\n",
      "\n",
      "estimate of P(S=1):\t0.285\n",
      "marginal of P(S=1):\t0.275\n"
     ]
    }
   ],
   "source": [
    "l1_estimate = gibbs_sample['L'].sum() / len(gibbs_sample)\n",
    "s1_estimate = gibbs_sample['S'].sum() / len(gibbs_sample)\n",
    "\n",
    "l1_actual = inference.query(['L'])['L'].values[1]\n",
    "s1_actual = inference.query(['S'])['S'].values[1]\n",
    "\n",
    "print(\"estimate of P(L=1):\", l1_estimate, sep=\"\\t\")\n",
    "print(\"marginal of P(L=1):\", l1_actual, sep=\"\\t\")\n",
    "print()\n",
    "print(\"estimate of P(S=1):\", s1_estimate, sep=\"\\t\")\n",
    "print(\"marginal of P(S=1):\", s1_actual, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, our estimate isn't too bad considering the low computational cost of sampling from the Markov chain (we didn't even bother to check if the chain was mixed!), but more complex graphical models won't be as easy to approximate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pgmpy.models import MarkovModel\n",
    "from pgmpy.factors.discrete import DiscreteFactor\n",
    "\n",
    "# Explained in next cell\n",
    "def generate_kite_chain_mrf(length, make_near_uniform=True):\n",
    "    def make_uniform_like_factor(for_vars):\n",
    "        factor_length = 2**(len(for_vars))\n",
    "        return DiscreteFactor(\n",
    "                    variables=list(map(lambda v : 'X' + str(v), for_vars)), \n",
    "                    cardinality=[2]*len(for_vars), \n",
    "                    values=[1]*factor_length\n",
    "                  )\n",
    "    def make_peaked_factor(for_vars):\n",
    "        factor_length = 2**(len(for_vars))\n",
    "        return DiscreteFactor(\n",
    "                    variables=list(map(lambda v : 'X' + str(v), for_vars)), \n",
    "                    cardinality=[2]*len(for_vars), \n",
    "                    values=[1 + 0 #np.random.uniform(-0.05, 0.05) \n",
    "                            for i in range(int(factor_length/2))] \\\n",
    "                        \"\"\"+ [0.001 + 0 #np.random.uniform(-0.05, 0.05)\n",
    "                            for i in range(int(factor_length/2))]\"\"\"\n",
    "                  )\n",
    "    edge_list = []\n",
    "    factor_list = []\n",
    "    chain_link = 0\n",
    "    while chain_link < length*3:\n",
    "        i = chain_link\n",
    "        # model structure\n",
    "        for e in [(i, i+2), (i+2, i+3), (i+3, i+1), (i+1, i), (i+1, i+2), (i, i+3)]:\n",
    "            edge_list.append(('X' + str(e[0]), 'X' + str(e[1])))\n",
    "        # factors\n",
    "        if make_near_uniform:\n",
    "            factor_list.append(make_uniform_like_factor([i, i+1, i+2, i+3]))\n",
    "        else:\n",
    "            factor_list.append(make_peaked_factor([i, i+1, i+2, i+3]))\n",
    "        chain_link += 3\n",
    "    markov_model = MarkovModel(edge_list)\n",
    "    markov_model.add_factors(*factor_list)\n",
    "    return markov_model\n",
    "    \n",
    "# Defining the model structure\n",
    "markov_model = generate_kite_chain_mrf(2, make_near_uniform=True)\n",
    "\n",
    "markov_model.check_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What I've done above is write a function that creates a Markov Random Field consisting of a series of complete graphs on 4 vertices (kites), each sharing two \"end\" vertices with other kites (except for the kites on the ends of the chain -- though it would be interesting to link the ends together and see how that affects our results). Note that what I call kites are not actual [kite graphs](http://mathworld.wolfram.com/KiteGraph.html).\n",
    "\n",
    "A junction tree representation is shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![student network](mrf.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each cluster/factor has the same values, but we can flip the boolean flag ```make_near_uniform``` in the function call to change that shared factor to a factor with values $0.5 \\pm \\epsilon$ for every possible state (near uniform) or to a higher variance factor with values $0.95\\pm\\epsilon$ whenever some $X_i$ in the factor is $j$ or $0.1\\pm\\epsilon$ whenever $X_i$ is $1-j$, where $\\epsilon$ is a small perturbation that varies. More colloquially, every factor has a single variable that has a high chance of being one value (0 or 1), but not the other (all values are binary). In this specific implementation, \"some $X_i$\" are always the tips of the kite chain and the vertices that connect each kite. \n",
    "\n",
    "If you're confused about the perturbations, don't be. They don't affect our results too much except to add some noise to the marginals.\n",
    "\n",
    "Let's see how our MCMC methods perform on such a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal estimates\n",
      "{'X0': 0.51000000000000001, 'X2': 0.50700000000000001, 'X3': 0.51900000000000002, 'X1': 0.50800000000000001, 'X5': 0.502, 'X6': 0.497, 'X4': 0.51500000000000001}\n",
      "\n",
      "actual marginals\n",
      "{'X0': 0.5, 'X2': 0.5, 'X3': 0.5, 'X1': 0.5, 'X5': 0.5, 'X6': 0.5, 'X4': 0.5}\n"
     ]
    }
   ],
   "source": [
    "# first, get the true marginals for our 'near uniform' distribution\n",
    "from pgmpy.inference import BeliefPropagation\n",
    "\n",
    "inference_markov = BeliefPropagation(markov_model)\n",
    "inference_markov.calibrate()\n",
    "marginals_markov = inference_markov.query(markov_model.nodes())\n",
    "\n",
    "# estimate the marginals with a gibbs chain\n",
    "gibbs_markov = GibbsSampling(markov_model)\n",
    "gibbs_markov_sample = gibbs_markov.sample(size=1000)\n",
    "\n",
    "print(\"marginal estimates\")\n",
    "print({i: gibbs_markov_sample[i].sum() / len(gibbs_markov_sample[i]) \n",
    "       for i in markov_model.nodes()})\n",
    "print()\n",
    "print(\"actual marginals\")\n",
    "print({k: marginals_markov[k].values[1] for k in marginals_markov})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Not bad for how little work we did (only 1000 samples from our Markov chain initialized with a random point). How well do we do on the peaked networked?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal estimates\n",
      "{'X0': 0.002, 'X2': 0.52200000000000002, 'X3': 0.0, 'X1': 0.47499999999999998, 'X5': 0.49299999999999999, 'X6': 0.52500000000000002, 'X4': 0.49299999999999999}\n",
      "\n",
      "actual marginals\n",
      "{'X0': 0.0010000000000000015, 'X2': 0.5, 'X3': 0.001, 'X1': 0.5, 'X5': 0.5, 'X6': 0.5, 'X4': 0.5}\n"
     ]
    }
   ],
   "source": [
    "markov_model_peaked = generate_kite_chain_mrf(2, make_near_uniform=False)\n",
    "\n",
    "# get true marginals for peaked distribution\n",
    "inference_markov_peaked = BeliefPropagation(markov_model_peaked)\n",
    "inference_markov_peaked.calibrate()\n",
    "marginals_markov_peaked = \\\n",
    "    inference_markov_peaked.query(markov_model_peaked.nodes())\n",
    "    \n",
    "# estimate marginals\n",
    "gibbs_markov_peaked = GibbsSampling(markov_model_peaked)\n",
    "gibbs_markov_sample_peaked = gibbs_markov_peaked.sample(size=1000)\n",
    "\n",
    "print(\"marginal estimates\")\n",
    "print({i: gibbs_markov_sample_peaked[i].sum() / len(gibbs_markov_sample_peaked[i]) \n",
    "       for i in markov_model_peaked.nodes()})\n",
    "print()\n",
    "print(\"actual marginals\")\n",
    "print({k: marginals_markov_peaked[k].values[1] for k in marginals_markov_peaked})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our chain is noticeably less accurate, particularly with respect to the variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X0': {(0, 0, 0): array([ 0.999,  0.001]),\n",
       "  (0, 0, 1): array([ 0.999,  0.001]),\n",
       "  (0, 1, 0): array([ 0.999,  0.001]),\n",
       "  (0, 1, 1): array([ 0.999,  0.001]),\n",
       "  (1, 0, 0): array([ 0.999,  0.001]),\n",
       "  (1, 0, 1): array([ 0.999,  0.001]),\n",
       "  (1, 1, 0): array([ 0.999,  0.001]),\n",
       "  (1, 1, 1): array([ 0.999,  0.001])},\n",
       " 'X1': {(0, 0, 0): array([ 0.5,  0.5]),\n",
       "  (0, 0, 1): array([ 0.5,  0.5]),\n",
       "  (0, 1, 0): array([ 0.5,  0.5]),\n",
       "  (0, 1, 1): array([ 0.5,  0.5]),\n",
       "  (1, 0, 0): array([ 0.5,  0.5]),\n",
       "  (1, 0, 1): array([ 0.5,  0.5]),\n",
       "  (1, 1, 0): array([ 0.5,  0.5]),\n",
       "  (1, 1, 1): array([ 0.5,  0.5])},\n",
       " 'X2': {(0, 0, 0): array([ 0.5,  0.5]),\n",
       "  (0, 0, 1): array([ 0.5,  0.5]),\n",
       "  (0, 1, 0): array([ 0.5,  0.5]),\n",
       "  (0, 1, 1): array([ 0.5,  0.5]),\n",
       "  (1, 0, 0): array([ 0.5,  0.5]),\n",
       "  (1, 0, 1): array([ 0.5,  0.5]),\n",
       "  (1, 1, 0): array([ 0.5,  0.5]),\n",
       "  (1, 1, 1): array([ 0.5,  0.5])},\n",
       " 'X3': {(0, 0, 0): array([ 0.5,  0.5]),\n",
       "  (0, 0, 1): array([ 0.5,  0.5]),\n",
       "  (0, 1, 0): array([ 0.5,  0.5]),\n",
       "  (0, 1, 1): array([ 0.5,  0.5]),\n",
       "  (1, 0, 0): array([ 0.5,  0.5]),\n",
       "  (1, 0, 1): array([ 0.5,  0.5]),\n",
       "  (1, 1, 0): array([ 0.5,  0.5]),\n",
       "  (1, 1, 1): array([ 0.5,  0.5])}}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf = generate_kite_chain_mrf(1, make_near_uniform=False)\n",
    "mc = GibbsSampling(mf)\n",
    "mc.transition_models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
